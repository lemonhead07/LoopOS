{
  "model": {
    "type": "transformer",
    "d_model": 128,
    "num_heads": 4,
    "num_layers": 2,
    "d_ff": 512,
    "vocab_size": 16000
  },
  "computation": {
    "mode": "pretraining",
    "method": "autoregressive",
    "description": "GPT-style pretraining on Wikipedia - Small test (AA directory, limited files)"
  },
  "training": {
    "learning_rate": 0.0003,
    "batch_size": 8,
    "num_epochs": 1,
    "max_length": 64,
    "random_seed": 42
  },
  "data": {
    "input_file": "data/pretraining/wiki/fullEnglish/AA/",
    "output_dir": "outputs/wiki_test",
    "tokenizer_vocab": "outputs/tokenizer_wiki.vocab",
    "max_files": 10
  },
  "generation": {
    "max_length": 50,
    "temperature": 0.8,
    "top_p": 0.9,
    "top_k": 40
  },
  "profiling": {
    "enabled": false,
    "report_top_n": 10
  }
}
