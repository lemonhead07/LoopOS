{
  "model": {
    "type": "transformer",
    "d_model": 384,
    "num_heads": 8,
    "num_layers": 6,
    "d_ff": 1536,
    "vocab_size": 16000
  },
  "computation": {
    "mode": "posttraining",
    "method": "chain_of_thought",
    "description": "Chain-of-thought reasoning training (optimized for i5-1135G7)"
  },
  "training": {
    "learning_rate": 0.00001,
    "batch_size": 16,
    "num_epochs": 3
  },
  "data": {
    "pretrained_weights": "models/pretrained_model.bin",
    "reasoning_examples": "data/reasoning_examples.txt",
    "output_dir": "outputs/chain_of_thought"
  }
}
